\documentclass[12pt, A4, twoside]{report}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

\usepackage[style=apa]{biblatex}
\addbibresource{thesis.bib}

\usepackage{subfiles} % Best loaded last in the preamble according to https://www.overleaf.com/learn/latex/Multi-file_LaTeX_projects#The_subfiles_package

\title{BNN Thesis}
\author{Philipp A. Hummel}
\date{\today}

\begin{document}

\begin{titlepage}
\maketitle
\end{titlepage}


\begin{abstract}
\subfile{chapters/00_abstract}
\end{abstract}


\tableofcontents


\chapter{Introduction}
\subfile{chapters/01_introduction}



\chapter{Background}
\subfile{chapters/02_background}



\chapter{LLB Ensemble}
\subfile{chapters/03_llb_ensemble}



\chapter{How many ensemble members do we need?}
\subfile{chapters/04_how_many_members}



\chapter{Comparing ensembles with HMC}
\subfile{chapters/05_comparison_to_mcmc}



\chapter{Conclusion}
\subfile{chapters/06_conclusion}



\chapter{Unsorted ideas}
\begin{itemize}
  \item For out of distribution data (i.e. when the IID assumption is violated) there are no guarantees for the bayesian theorems ( according to S). But it does work reasonably well when using HMC (2018 | Sufficient Conditions for Idealized Models to Have No Adversarial Examples | Gal, Smith). Maybe there is some interesting math because we are using discriminative models and not generative models.
  
  Answer:
  Well first, what do we mean by OOD? We mean out of the distribution of X, but still within the same distribution of y|X. Otherwise we indeed have no chance and no guarantees since E[y|X] might change (e.g. the whole function might be shifted by +5). But what happens in a discriminative / conditional model when we get new data points from a different distribution of X? Well we have used the training data, to learn something about the posterior distribution over functions. If our parametric model was very flexible, the posterior distribution of functions should still be super wide outside the range of the X seen so far, but I see no principled problem in encountering these new data points and measuring test log likelihood on them. And I still think this is quite necessary for practice. Compare “Bayesian Data Analysis” 3rd edition 2014 Gelman, Chapter 14.1.
  \item Bayesian linear regression; when you want to have completely separate prior distributions for the weights and the noise standard deviation, you end up with a semi conjugate model. That means that the marginal posterior distributions for each variable are not tractable. However, the conditional posterior distributions are tractable. Then you can easily use a Gibbs sampler for computing the posterior by sampling. I have not seen it clearly stated, but it seems to me that the posterior predictive distribution in this case is also not analytically tractable.
  \item Explaining Bayesian Linear Regression
  \item We should say something like "Great care was taken to ensure that all models considered here are actually approximating the same posterior distribution". Then we can explain that all models need to model the likelihood distribution's noise variance explicitly and that we chose to model the noise variance homoscedastically. When we try to make a map model find a local maximum of the same posterior (as HMC) then using L2 regularization can only work when we fix the noise variance beforehand. So in this case it was necessary to instead add a loss that is equivalent to the log prior
  \item What about modelling heteroscedasticity? I would expect that these models perform better (even when the noise is actually homoscedastic? Probably not, but in reality it probably rarely is actually homoscedastic.). When we only want to learn something about ensembling, using a homoscedastic model is not a problem. When we want to show that our model has superior performance (i.e. for the LLB Ensemble case) it might be most honest if we also compared to a heteroscedastic model. Or at least mention that future work should compare to a heteroscedastic model on real-world data sets, and that LLB is not easy to do in that case (but we can imagine doing a VI approach for that case, where it would likely be tractable to model weight covariances, since we are only concerned with the last layer. (So this would only be a multivariate Normal distribution. Can we show that the posterior then must also be a normal distribution? Then VI could even find the true parameters?)). 
  \item The Laplace approximation should be part of the review of existing methods and should be part of the qualitative comparison. 
  \item Potential scale reduction as a tool for diagnosing HMC convergence might not work very well for bayesian neural networks. (Potential scale reduction is never a sufficient criterion) It is just as sufficient for convergence as in other cases, but it is much less necessary. This is because there are so many weight space symmetries and might not be necessary (or possible) to visit them all. Maybe a better metric would be to look at the predictive distributions' distance to each other since we only care about them.
  \item Should we include "Single memeber better than ensemble" experiments? Well we should mention somewhere that ensembles must be better than the average of the members in terms of log likelihood and RMSE. Then we can say: it is still possible that a single lucky member network is better than the ensemble. But we find this is mostly not the case. Can be an interesting sidenote, but only if it's not too much work. And it should probably be repeated on at least ~3 data sets. So probably it is too much work.
  \item mode changes under re parameterization argument against map networks.
  \item LLB network/ensemble concern that it becomes overconfident when too much data is available. Toy Experiment apparently shows that this is not the case.
  \item I should mention that I put a lot of effort in using tensorflow probability's multi chain framework for the BNN with HMC so that multiple chains are really quick to compute. And for small networks indeed running e.g. 128 chains in parallelIs only a few times slower then running only one chain.  For large networks however not so much is gained. \cite{lao2020tfp}
\end{itemize}
\printbibliography

\end{document}
