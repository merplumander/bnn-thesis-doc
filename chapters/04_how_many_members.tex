\documentclass[../thesis.tex]{subfiles}

\begin{document}

For all types of ensembles a natural and very important question is: How many ensemble members do we need?

- The literature seems to suggest that 5-10 are enough for good performance. But there has not been a thorough experimental study as far as we know.
Given the supposed great complexity of BNN posteriors, shouldn't we be surprised about such a low number?

- Ensemble sizes UCI and UCI Gap Experiment (also introduce ideas about IID vs OOD data i.e. Interpolation vs. Extrapolation. OOD of X but not out of distribution of y|X! Otherwise we have of course no guarantees.) Log likelihood and RMSE.
-> Result: 5-10 is indeed the magic range, after which the returns are strongly diminishing.
-> convergence behaviour of LLB ensemble similar to map ensemble. Constant difference between the two independent of number of members?

(We also had the data for the experiment where we compare these methods with VI on all UCI datasets, but I guess this shouldnt be a separate figure since only new thing is VI. Maybe we should just include VI as a comparison point in the ensemble sizes figures. 
S says this should be separate figure, so we can show it here. This will give us a clear, uncluttered comparison all LLB ensembles to other methods.)



% (predictive distribution convergence?)
% (not only avergae log likelihood but also worst case or best case log likelihood or also looking at quantiles 0-25\%, 25-75\% and 75+)
% (predicitve dist on measurement set)
% How different are the members predictive distributions to eacht other?\cite{fort2019}

% Given the supposed great complexity of Bayesian neural network posteriors (e.g. because of weight space symmetries), it seems surprising that five or ten ensemble members are enough. But the natural question is what do we mean by enough. Apparently the performance (in terms of log likelihood and mean squared error) does not improve with more members, but is that because we have approximated the true bayesian neural network posterior sufficiently well, or at least the true posterior predictive distribution? Have we even reached the performance of the true posterior predictive distribution (let alone its true form)? In the following chapter we will compare ensembles to bayesian neural networks approximated by MCMC sampling to understand these questions in more detail.

% Have we approximated the bayesian neural network's predictive distribution or performance yet? 
% What is the convergence behaviour of samples from the (HMC) posterior? Are MAP networks / ensembles in some sense better than samples from the posterior? Since they are the modes of the dist. they might represent it better.


\end{document}