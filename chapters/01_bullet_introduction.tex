\documentclass[../thesis.tex]{subfiles}

\begin{document}

Probability theory provides mathematical framework for dealing with uncertainties. Cox, Jaynes $\rightarrow$ rational observer updates beliefs using probability theory.
\bigskip

Derive Bayes theorem generally. $\rightarrow$ Allows unobserved variables (like parameters of a model) to be inferred by data.
\bigskip

Conditional modelling (regression, classification) focusing on the distribution of $y|X$. Functions with global / local properties $\rightarrow$ what can we learn about the function from empirical data? $\rightarrow$ depending on our assumptions we can learn something about the function from data globally / locally (important for IID vs OOD)
\bigskip

Introduce linear regression model. Can also be done classically with point estimates that can also be derived from error minimization. Through the bayesian lens a point estimate for the parameters can be viewed as using a Dirac delta distribution to approximate the posterior. This approximation can be good when the posterior is strongly peaked around its mode, which usually happens when we have much more data than parameters, or it can be bad e.g.\ when the posterior is multimodal, as can happen in non-linear models with many parameters (like neural networks) . Both Bayesian and classic linear regression can be solved in closed form. Point estimates plagued by overfitting and overconfident predictions.
\bigskip

Neural networks as flexible function approximators. Basis functions can adapt to data and act as a feature extractor. Empirically more useful than hand-engineered features. Last layer roughly acts as linear regression. MAP estimate can no longer be derived in closed form $\rightarrow$ A need to use iterative procedures like gradient ascent. Bayesian NNs hard to approximate. $\rightarrow$ classically use either MCMC or VI. Recently ensembles have been introduce as a non-Bayesian way of obtaining the uncertainty in the prediction of the neural network, and have been empirically shown to provide state of the art results. Wilson... have interpreted ensembles from a Bayesina viewpoint and provide more arguments in favor of using ensembles. In this work we take a closer look at ensembling methods through the Bayesian lens. !! cite: Lakshminarayanan, Ovadia, Wilson !!
\bigskip

Bayesian deep learning promises great predictions (no overfitting) and useful uncertainties (model knows when it does not know). But it also poses challenges. Neural networks are often thought of as black box function approximators since the inner workings are not well understood. This makes formulating prior knowledge hard. Often we do have prior knowledge about the distribution of functions but translating this knowledge to the realm of weights is a though problem. Usually we care about priors over functions not weights ($\rightarrow$ GPs). 

``model knows when it does not know'' is important when there is a shift in the dataset (distribution of $X$) at test time. $\rightarrow$ OOD Data (discuss difference between shift in distribution of $X$ vs.\ $y$ since we are modelling $p(y|X)$)

\end{document}