\documentclass[../thesis.tex]{subfiles}

\begin{document}

Straightforward combination.

Weightspace visualization


\section{Qualitative comparison to the most popular Bayesian Neural Network Approximations}
(See Siemens slides)

Bias:

Computational Cost: 

Convergence:  Easily Checked; MAP network not imporving, Last Layer BLR in closed form; HMC hard to diagnose; VI also easy

Adaptability: Online updates for Bayesian linear regression. MAP feature extractor can be trained further ((transfer learning)). HMC adapting samples is problematic.

More dimensions: see S's thesis 2.2.3.

Also compare to Laplace


\section{Toy performance}
Can we find toy circumstances where ensembles perform badly and can LLB ensembles help in those cases?

-> Toy experiment with linear outer edges (have more toy examples. Include them?)

\end{document}